{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yushentang/RVC-Retrieval-based-Voice-Conversion-Colab/blob/main/RVC_For_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JnMq1gOzwAR"
      },
      "outputs": [],
      "source": [
        "# @title 克隆仓库\n",
        "%rm -rf /content/RVC-Retrieval-based-Voice-Conversion-Colab\n",
        "%cd /content\n",
        "!git clone --depth=1 https://github.com/yushentang/RVC-Retrieval-based-Voice-Conversion-Colab.git\n",
        "%cd /content/RVC-Retrieval-based-Voice-Conversion-Colab\n",
        "!mkdir -p pretrained uvr5_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9ElBFn_lOIHm"
      },
      "outputs": [],
      "source": [
        "# @title 配置运行环境\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6xsQMMHMb9Uj"
      },
      "outputs": [],
      "source": [
        "# @title 下载基础模型\n",
        "!apt install -y aria2\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/D32k.pth -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/pretrained -o D32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/D40k.pth -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/pretrained -o D40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/D48k.pth -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/pretrained -o D48k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/G32k.pth -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/pretrained -o G32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/G40k.pth -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/pretrained -o G40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/G48k.pth -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/pretrained -o G48k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0D32k.pth -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/pretrained -o f0D32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0D40k.pth -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/pretrained -o f0D40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0D48k.pth -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/pretrained -o f0D48k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0G32k.pth -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/pretrained -o f0G32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0G40k.pth -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/pretrained -o f0G40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0G48k.pth -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/pretrained -o f0G48k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/D32k.pth -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/pretrained_v2 -o D32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/D40k.pth -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/pretrained_v2 -o D40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/D48k.pth -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/pretrained_v2 -o D48k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/G32k.pth -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/pretrained_v2 -o G32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/G40k.pth -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/pretrained_v2 -o G40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/G48k.pth -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/pretrained_v2 -o G48k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0D32k.pth -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/pretrained_v2 -o f0D32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0D40k.pth -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/pretrained_v2 -o f0D40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0D48k.pth -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/pretrained_v2 -o f0D48k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0G32k.pth -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/pretrained_v2 -o f0G32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0G40k.pth -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/pretrained_v2 -o f0G40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0G48k.pth -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/pretrained_v2 -o f0G48k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/uvr5_weights/HP2-人声vocals+非人声instrumentals.pth -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/uvr5_weights -o HP2-人声vocals+非人声instrumentals.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/uvr5_weights/HP5-主旋律人声vocals+其他instrumentals.pth -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/uvr5_weights -o HP5-主旋律人声vocals+其他instrumentals.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/spaces/zomehwh/rvc-models/resolve/main/hubert_base.pt -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/assets/hubert -o hubert_base.pt\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/rmvpe.pt -d /content/RVC-Retrieval-based-Voice-Conversion-Colab/assets/rmvpe -o rmvpe.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jwu07JgqoFON"
      },
      "outputs": [],
      "source": [
        "# @title 挂载谷歌云盘\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Mwk7Q0Loqzjx"
      },
      "outputs": [],
      "source": [
        "# @title 从谷歌云盘加载打包好的数据集到/content/dataset\n",
        "\n",
        "# @markdown 数据集位置\n",
        "DATASET = \"/content/drive/MyDrive/datasets/RVC/src.zip\"  # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "!mkdir -p /content/dataset\n",
        "!unzip -d /content/dataset -B {DATASET}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OVQoLQJXS7WX"
      },
      "outputs": [],
      "source": [
        "# @title 从谷歌云盘恢复pth （初次使用不需要执行）\n",
        "# @markdown 需要自己查看logs文件夹下模型的文件名，手动修改下方命令末尾的文件名\n",
        "\n",
        "# @markdown 模型名\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "# @markdown 模型epoch\n",
        "MODELEPOCH = 7500  # @param {type:\"integer\"}\n",
        "\n",
        "!mkdir -p /content/RVC-Retrieval-based-Voice-Conversion-Colab/logs/{MODELNAME}\n",
        "\n",
        "!cp /content/drive/MyDrive/{MODELNAME}_D_{MODELEPOCH}.pth /content/RVC-Retrieval-based-Voice-Conversion-Colab/logs/{MODELNAME}/G_{MODELEPOCH}.pth\n",
        "!cp /content/drive/MyDrive/{MODELNAME}_G_{MODELEPOCH}.pth /content/RVC-Retrieval-based-Voice-Conversion-Colab/logs/{MODELNAME}/D_{MODELEPOCH}.pth\n",
        "!cp /content/drive/MyDrive/*.index /content/\n",
        "!cp /content/drive/MyDrive/*.npy /content/\n",
        "!cp /content/drive/MyDrive/{MODELNAME}{MODELEPOCH}.pth /content/RVC-Retrieval-based-Voice-Conversion-Colab/weights/{MODELNAME}.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxFlHIGoZNK1"
      },
      "source": [
        "# Web运行RVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WTevfT40FnC"
      },
      "outputs": [],
      "source": [
        "# @title 方案一：直接运行脚本（使用Gradio获得web访问）\n",
        "%cd /content/RVC-Retrieval-based-Voice-Conversion-Colab\n",
        "#%load_ext tensorboard\n",
        "#%tensorboard --logdir /content/RVC-Retrieval-based-Voice-Conversion-Colab/logs\n",
        "!python infer-web.py --colab --pycmd python3 --port 7890"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0SaYzc5S_Dg"
      },
      "outputs": [],
      "source": [
        "# @title 方案二：使用pyngrok运行脚本\n",
        "#%load_ext tensorboard\n",
        "#%tensorboard --logdir /content/RVC-Retrieval-based-Voice-Conversion-Colab/logs\n",
        "!pip install pyngrok\n",
        "from pyngrok import ngrok\n",
        "# @markdown Ngrok Authtoken 在 https://dashboard.ngrok.com 申请\n",
        "Authtoken = \"2x0F1HSAx3Cz9qKh37N024hUsun_ghv5kBY5A6CusTNVRo9J\"  # @param {type:\"string\"}\n",
        "ngrok.set_auth_token(Authtoken)       # 在 https://dashboard.ngrok.com 申请\n",
        "# 假设 Gradio 启动在 7860 端口\n",
        "public_url = ngrok.connect(7860, \"http\")\n",
        "print(\"🌐 ngrok 公网访问地址:\", public_url)\n",
        "# 然后启动你的 WebUI，保证监听 0.0.0.0:7860\n",
        "!python infer-web.py --pycmd python3 --port 7860\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FgJuNeAwx5Y_"
      },
      "outputs": [],
      "source": [
        "# @title 模型文件备份到谷歌云盘\n",
        "# @markdown 需要自己查看logs文件夹下模型的文件名，手动修改下方命令末尾的文件名\n",
        "\n",
        "# @markdown 模型名\n",
        "MODELNAME = \"jst_colab\"  # @param {type:\"string\"}\n",
        "# @markdown 模型epoch\n",
        "MODELEPOCH = 1520  # @param {type:\"integer\"}\n",
        "\n",
        "!cp /content/RVC-Retrieval-based-Voice-Conversion-Colab/logs/{MODELNAME}/G_{MODELEPOCH}.pth /content/drive/MyDrive/{MODELNAME}_D_{MODELEPOCH}.pth\n",
        "!cp /content/RVC-Retrieval-based-Voice-Conversion-Colab/logs/{MODELNAME}/D_{MODELEPOCH}.pth /content/drive/MyDrive/{MODELNAME}_G_{MODELEPOCH}.pth\n",
        "!cp /content/RVC-Retrieval-based-Voice-Conversion-Colab/logs/{MODELNAME}/added_*.index /content/drive/MyDrive/\n",
        "!cp /content/RVC-Retrieval-based-Voice-Conversion-Colab/logs/{MODELNAME}/total_*.npy /content/drive/MyDrive/\n",
        "\n",
        "!cp /content/RVC-Retrieval-based-Voice-Conversion-Colab/weights/{MODELNAME}.pth /content/drive/MyDrive/{MODELNAME}{MODELEPOCH}.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z140MytAYySd"
      },
      "source": [
        "# 若尝试运行Web界面时提示执行代码被禁止则可以使用指令来运行脚本进行模型训练"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZKAyuKb9J6dz"
      },
      "outputs": [],
      "source": [
        "# @title 音频文件预处理\n",
        "# @markdown 模型名\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "# @markdown 采样率\n",
        "BITRATE = 48000  # @param {type:\"integer\"}\n",
        "# @markdown 使用的进程数\n",
        "THREADCOUNT = 8  # @param {type:\"integer\"}\n",
        "\n",
        "!python trainset_preprocess_pipeline_print.py /content/dataset {BITRATE} {THREADCOUNT} logs/{MODELNAME} True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CrxJqzAUKmPJ"
      },
      "outputs": [],
      "source": [
        "# @title 提取音高特征\n",
        "# @markdown 模型名\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "# @markdown 使用的进程数\n",
        "THREADCOUNT = 8  # @param {type:\"integer\"}\n",
        "# @markdown 音高提取算法 可选\"harvest\" \"pm\" \"dio\" \"rmvpe\"\n",
        "ALGO = \"rmvpe\"  # @param {type:\"string\"}\n",
        "\n",
        "!python3 extract_f0_print.py logs/{MODELNAME} {THREADCOUNT} {ALGO}\n",
        "\n",
        "!python3 extract_feature_print.py cpu 1 0 0 logs/{MODELNAME} True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMLPLKOaKj58"
      },
      "outputs": [],
      "source": [
        "# @title 训练模型\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/RVC-Retrieval-based-Voice-Conversion-Colab/logs\n",
        "# @markdown 模型名\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "# Colab只有单卡，故无需考虑\n",
        "USEGPU = \"0\"\n",
        "# @markdown 批大小\n",
        "BATCHSIZE = 32  # @param {type:\"integer\"}\n",
        "# @markdown 停止的epoch\n",
        "MODELEPOCH = 3200  # @param {type:\"integer\"}\n",
        "# @markdown 保存epoch间隔\n",
        "EPOCHSAVE = 100  # @param {type:\"integer\"}\n",
        "# @markdown 采样率\n",
        "MODELSAMPLE = \"48k\"  # @param {type:\"string\"}\n",
        "# @markdown 是否缓存训练集\n",
        "CACHEDATA = 1  # @param {type:\"integer\"}\n",
        "# @markdown 是否仅保存最新的ckpt文件\n",
        "ONLYLATEST = 0  # @param {type:\"integer\"}\n",
        "\n",
        "!python3 train_nsf_sim_cache_sid_load_pretrain.py -e lulu -sr {MODELSAMPLE} -f0 1 -bs {BATCHSIZE} -g {USEGPU} -te {MODELEPOCH} -se {EPOCHSAVE} -pg pretrained/f0G{MODELSAMPLE}.pth -pd pretrained/f0D{MODELSAMPLE}.pth -l {ONLYLATEST} -c {CACHEDATA}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "04wbdjCgbKdq"
      },
      "outputs": [],
      "source": [
        "# @title 模型文件备份到谷歌云盘\n",
        "# @markdown 需要自己查看logs文件夹下模型的文件名，手动修改下方命令末尾的文件名\n",
        "\n",
        "# @markdown 模型名\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "# @markdown 模型epoch\n",
        "MODELEPOCH = 9600  # @param {type:\"integer\"}\n",
        "\n",
        "!cp /content/RVC-Retrieval-based-Voice-Conversion-Colab/logs/{MODELNAME}/G_{MODELEPOCH}.pth /content/drive/MyDrive/{MODELNAME}_D_{MODELEPOCH}.pth\n",
        "!cp /content/RVC-Retrieval-based-Voice-Conversion-Colab/logs/{MODELNAME}/D_{MODELEPOCH}.pth /content/drive/MyDrive/{MODELNAME}_G_{MODELEPOCH}.pth\n",
        "!cp /content/RVC-Retrieval-based-Voice-Conversion-Colab/logs/{MODELNAME}/added_*.index /content/drive/MyDrive/\n",
        "!cp /content/RVC-Retrieval-based-Voice-Conversion-Colab/logs/{MODELNAME}/total_*.npy /content/drive/MyDrive/\n",
        "\n",
        "!cp /content/RVC-Retrieval-based-Voice-Conversion-Colab/weights/{MODELNAME}.pth /content/drive/MyDrive/{MODELNAME}{MODELEPOCH}.pth"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}